<!DOCTYPE html>
<html>
<body>
<h1>Simple RAG System for MCP Server Support</h1>

<p>A lightweight Retrieval-Augmented Generation (RAG) system designed to support an MCP server by providing information retrieval and code generation capabilities.</p>

<h2>Overview</h2>

<p>This system uses OpenAI embeddings to create a simple but effective vector search over documentation, allowing it to:</p>

<ol>
<li>Answer questions about documentation (inform)</li>
<li>Provide context for code generation (do code)</li>
<li>Support API calls through a web interface</li>
<li>Generate AI responses using OpenAI's completions API</li>
</ol>

<h2>Features</h2>

<ul>
<li>Simple document processing with text chunking</li>
<li>Vector embeddings via OpenAI API</li>
<li>In-memory vector storage with cosine similarity search</li>
<li>Web UI for interactive queries</li>
<li>API endpoints for MCP server integration</li>
<li>Deployment ready for Replit</li>
<li>Server-Sent Events (SSE) for streaming responses in real-time</li>
<li>AI-generated responses using OpenAI's completions API</li>
<li>Embedding cache to avoid regenerating embeddings</li>
</ul>

<h2>Setup and Deployment</h2>

<h3>Local Development</h3>

<ol>
<li>Install dependencies:
<pre><code>pip install -r requirements.txt</code></pre></li>

<li>Set up your OpenAI API key:
<pre><code>export OPENAI_API_KEY=your_api_key_here</code></pre></li>

<li>Run the application:
<pre><code>python3 app.py</code></pre></li>
</ol>

<h2>Testing</h2>

<p>Run the test scripts to verify that everything is working correctly:</p>

<pre><code># Test the OpenAI completions integration
python test_openai.py

# Test the local API endpoints
python test_local.py

# Test the streaming SSE endpoint
python test_sse.py
</code></pre>
</body>
</html>
